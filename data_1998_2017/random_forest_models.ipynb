{"cells":[{"cell_type":"markdown","source":["#IST718 Project - Google and NCAA Women's Basketball Tournament Prediction\n\n#Random Forest Classifier Machine learning algorithm to build 20-year predictive model\n\n@authors\nSanjana Rajagopala,\nShefali Vajramatti,\nApoorva Rajendra Angre,\nSandya Madhavan"],"metadata":{}},{"cell_type":"code","source":["#IMPORT ALL THE REQUIRED PACKAGES\nimport pandas as pd\nfrom pyspark.ml import feature\nfrom pyspark.ml.classification import LogisticRegression\n#from Regr import LinearRegression\nfrom pyspark.ml import classification\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SQLContext\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.sql import functions as fn\nfrom pyspark.sql.types import IntegerType\nimport numpy as np\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\nfrom pyspark.sql import functions as sf\nfrom pyspark.ml.feature import StringIndexer"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Read the required data from the CSV files uploaded in the FileStore dbfs of the Databricks environment\nwteamDF = spark.read.csv(\"/FileStore/tables/WTeams.csv\", header=True, inferSchema= True)\nlteamDF = spark.read.csv(\"/FileStore/tables/WTeams.csv\", header=True, inferSchema= True)\n\n#Read the RegularSeasons CSV File\nregularSeasonsDF = spark.read.csv(\"/FileStore/tables/WRegularSeasonCompactResults.csv\", header=True, inferSchema= True)\n\n#Read the Seeds and Slots CSV Files\nseedsDF = spark.read.csv(\"/FileStore/tables/WNCAATourneySeeds.csv\", header=True, inferSchema= True)\n\nslotsDF = spark.read.csv(\"/FileStore/tables/WNCAATourneySlots.csv\", header=True, inferSchema=True)\n\n#Read the TourneyResults CSV File\nCompactDF = spark.read.csv(\"/FileStore/tables/WNCAATourneyCompactResults.csv\", header=True, inferSchema= True)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Convert into Pandas DF from sql.dataframe for initial manipulation of data\nwteamDF = wteamDF.toPandas()\nlteamDF = lteamDF.toPandas()\nregularSeasonsDF = regularSeasonsDF.toPandas()\nslotsDF = slotsDF.toPandas()\nseedsDF = seedsDF.toPandas()\n\n#Rename the column to WTeamName\nwteamDF.columns = ['WTeamID', 'WTeamName']\nlteamDF.columns = ['LTeamID', 'LTeamName']\n\n#Maitain a copy of the original data\nNewseedsDF=seedsDF\n\nCompactDF = CompactDF.toPandas()\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Create the DICTIONARY - team id,season as key and seed as value\nseedsdict={}\nfor row in NewseedsDF.iterrows():\n  seedsdict[(row[1][\"Season\"], row[1][\"TeamID\"])] = row[1][\"Seed\"]\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Merge the Season and team ID details from results DF and team DF \ntemp_wCol = []\ntemp_lCol = []\nfor row in CompactDF.iterrows():\n  year = row[1]['Season']\n  wteamid = row[1]['WTeamID']\n  lteamid = row[1]['LTeamID']\n  temp_wCol.append(seedsdict[(year,wteamid)])\n  temp_lCol.append(seedsdict[(year,lteamid)])\n  "],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Add the corresponding seed values into the dataframe\nCompactDF['WSeed'] = temp_wCol\nCompactDF['LSeed'] = temp_lCol"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Define weights for the seeds of each team - Meaning keep the highest weight of 16 for the team with Seed 1\nweights_dict = {}\nj = 1\nfor i in range(16,0,-1):\n  weights_dict[j] = i\n  j+=1\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#PRE_PROCESSING THE DATAFRAME \n\ntemp_win = []\nwseed_num = []\nlseed_num = []\ndiff_seed = []\nloc_col = []\ndiff_score = []\nlow_team = []\nhigh_team = []\n\nfor row in CompactDF.iterrows():\n  \n  team_1 = row[1]['WTeamID']\n  team_2 = row[1]['LTeamID']\n  loc_val = row[1]['WLoc']\n  wseed = row[1]['WSeed']\n  lseed =row[1]['LSeed']\n  \n  #Maintain the win column value as 1 if the team with lower teamID has won in the match\n  if(team_1<team_2):\n    temp_win.append(1)\n    low_team.append(team_1)\n    high_team.append(team_2)\n  else:\n    temp_win.append(0)\n    high_team.append(team_1)\n    low_team.append(team_2)\n    \n  #Give the highest weight when played in the home ground, least of outside home, medium vlaue otherwise   \n  if(loc_val == 'H'):\n    loc_col.append(3)\n  elif(loc_val == 'N'):\n    loc_col.append(2)\n  elif(loc_val=='A'):\n    loc_col.append(1)\n    \n  #Maintain the difference between seeds of the teams  \n  temp_val = abs(weights_dict[int(wseed[1:])] - weights_dict[int(lseed[1:])])\n  diff_seed.append(temp_val)\n  \n  #Maintain the column with difference between scores of the teams\n  diff_score.append(abs(row[1]['WScore'] - row[1]['LScore']))\n  "],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Add the above obtained lists as columns into the DF\nCompactDF['WLProb'] = temp_win\nCompactDF['Seed_Diff'] = diff_seed\nCompactDF['Loc'] = loc_col\nCompactDF['Score_Diff'] = diff_score\nCompactDF['Low_team'] = low_team\nCompactDF['High_team'] = high_team"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Check the results of the pre-processing\nCompactDF[:5]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Conversion into the Spark SQL Dataframe\nsqlCtx = SQLContext(sc)\nsql_compactDF = sqlCtx.createDataFrame(CompactDF)\n\n#Rename the result column with the name label so that all the algorithms can be applied without any problems\nsql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["sql_compactDF.show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#FEATURE ENGINEERING\n\n#Definition of new features from existing data\n\n#Obtain the totalMatches played and win percentage of the team in respective season\n\nwDF = sql_compactDF.groupBy(['Season','WTeamID']).agg(fn.sum('label').alias('won'), fn.count('Season').alias('WCount'))\nlDF = sql_compactDF.groupBy(['Season','LTeamID']).agg(fn.count('Season').alias('LCount'))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Rename and maintain a clean DF\nwDF = wDF.selectExpr(\"WTeamID as teamID\", \"Season\", \"won\", \"WCount\")\nlDF = lDF.selectExpr(\"LTeamID as teamID\", \"Season\", \"LCount\")"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Create a DF of matches with the above combined details\nmatchDF = wDF.join(lDF, (wDF.teamID== lDF.teamID) & (wDF.Season==lDF.Season), how='right')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["display(matchDF)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["matchDF = matchDF.withColumn(\"totalMatches\", sum([matchDF[col] for col in ['WCount', 'LCount']]))\n#Computing the win percetage for the individaul teams\nmatchDF=matchDF.withColumn(\"winPercentage\", fn.col('WCount')/fn.col('totalMatches') )\n#Create Pandas DF only for this manipulation\n#Renaming and selecting required data - avoiding redundancy\nmatch_pd_DF = matchDF.toPandas()\nmatch_pd_DF = match_pd_DF.iloc[:,[0,1,8]]\nmatchDF = sqlCtx.createDataFrame(match_pd_DF)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#Count and display the DF to ensure the join has not missed any data rows and other details\ndisplay(matchDF)\nprint(matchDF.count())\n#Expect NaN because of the null values introduced during the join"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Add the details from matchDF to the initial integrated DF\n\nwinPercentage_DF = sql_compactDF.join(matchDF, (matchDF.teamID== sql_compactDF.WTeamID) & (sql_compactDF.Season==matchDF.Season), how='left').select('DayNum', sql_compactDF.Season, 'WTeamID', 'WScore', 'LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc', \"Score_Diff\",fn.col('winPercentage').alias('W_win_percentage'))\n\nwinPercentage_DF = winPercentage_DF.join(matchDF, (matchDF.teamID== winPercentage_DF.LTeamID) & (winPercentage_DF.Season==matchDF.Season), how='left').select('DayNum', winPercentage_DF.Season, 'WTeamID', 'WScore', 'LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc' ,\"Score_Diff\",'W_win_percentage',fn.col('winPercentage').alias('L_win_percentage'))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#Obtain the percentage as per the periods - 1998 to 2005; 2006 to 2010; 2011 to 2015; 2016 to 2017\n#This further used as features in the models\n\ngroupedTeams_DF_1 = matchDF.where((fn.col('Season').cast(IntegerType())>=1998) & (fn.col('Season').cast(IntegerType())<=2005)).groupBy('teamID').agg(fn.avg('winPercentage').alias('1998_2005_win_percentage'))\n\n#Repeat the grouping for remianing periods\ngroupedTeams_DF_2 = matchDF.where((fn.col('Season').cast(IntegerType())>=2006) & (fn.col('Season').cast(IntegerType())<=2010)).groupBy('teamID').agg(fn.avg('winPercentage').alias('2006_2010_win_percentage')) \ngroupedTeams_DF_3 = matchDF.where((fn.col('Season').cast(IntegerType())>=2011) & (fn.col('Season').cast(IntegerType())<=2015)).groupBy('teamID').agg(fn.avg('winPercentage').alias('2011_2015_win_percentage'))\ngroupedTeams_DF_4 = matchDF.where((fn.col('Season').cast(IntegerType())>=2016) & (fn.col('Season').cast(IntegerType())<=2017)).groupBy('teamID').agg(fn.avg('winPercentage').alias('2016_2017_win_percentage')) "],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Removing null values \nwinPercentage_DF=winPercentage_DF.na.fill(0)\n\n#Display to check the final DF\ndisplay(winPercentage_DF)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Join the data frame with the compact data frame\nwinPercentage_DF=groupedTeams_DF_1.join(winPercentage_DF, winPercentage_DF.WTeamID == groupedTeams_DF_1.teamID, how='right').select('DayNum', winPercentage_DF.Season, 'WTeamID', 'WScore', 'LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc' ,\"Score_Diff\",'W_win_percentage', 'L_win_percentage', '1998_2005_win_percentage')\nwinPercentage_DF=groupedTeams_DF_2.join(winPercentage_DF, winPercentage_DF.WTeamID == groupedTeams_DF_2.teamID, how='right')\nwinPercentage_DF=groupedTeams_DF_3.join(winPercentage_DF, winPercentage_DF.WTeamID == groupedTeams_DF_3.teamID, how='right')\nwinPercentage_DF=groupedTeams_DF_4.join(winPercentage_DF, winPercentage_DF.WTeamID == groupedTeams_DF_4.teamID, how='right')\n"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Removing redundant columns\nwpandasDF=winPercentage_DF.toPandas()\nwpandasDF=wpandasDF.drop('teamID', axis=1)\n\n#Creating spark sql dataframe\nwinPercentage_DF=sqlCtx.createDataFrame(wpandasDF)\n#Removing null values\nwinPercentage_DF=winPercentage_DF.na.fill(0)\n\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Display and count to check the results\ndisplay(winPercentage_DF)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["winPercentage_DF.printSchema()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#INFERENCE OF THE ADDED FEATURES\n#Checkimg the correlation between win percentages of each period with label\nwinPercentage_DF.select(fn.corr('1998_2005_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('Loc', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('2006_2010_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('2011_2015_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('Score_Diff', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('Seed_Diff', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('W_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('L_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('2016_2017_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#Feature Definition and Vector Assembler creation\n##############################################   MODEL - 1 #####################################################\n#Initial Set of Features with only the simple columns\n#DayNum - With the higher day number means games played at later stages. Hence, add as feature so that it means a better performance\n#WTeamID and LTeamID - the IDs indicate the possibility in that match up\n#Score_Diff - Difference between win and lose scores of the match\n#Seed_Diff - Difference between seeds of the two playing teams\n#NUMOT - Number of Overtimes in the match\n#Loc - Played at home, outside or neither\nfeatureCols_1 = [\"WTeamID\",\"DayNum\", \"Score_Diff\", \"Loc\", \"Seed_Diff\", \"NumOT\"]\n#set the input and output column names**\nassembler_1 = feature.VectorAssembler(inputCols = featureCols_1, outputCol = \"features\")"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# Split dataset randomly into Training , Validation and Test Datasets\ntrainingData, validationData, testData = winPercentage_DF.randomSplit([0.6,0.3,0.1])"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Train a Random Forest Classifier model\nrandom_for_1 = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Chain vecAssembler and Logistic regression model  \npipeline_1 = Pipeline(stages=[assembler_1, random_for_1])\n\n# Run stages in pipeline and train model\nmodel_1 = pipeline_1.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["#Determine the validation accuracy for model selection\nval_predictions_1 = model_1.transform(validationData)\n"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["#Determine the testing accuracy for the model performance\ntest_predictions_1 = model_1.transform(testData)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["#Define the evaluator to obtain the areaUnderROC or the AUC score of the model\nevaluator = BinaryClassificationEvaluator()\n"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["#Display the accuracies\nprint(\"The AUC metric for the validation dataset of model-1\", evaluator.evaluate(val_predictions_1))\nprint(\"The AUC metric for the testing dataset of model-1\", evaluator.evaluate(test_predictions_1))\n"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["val_predictions_1.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["#Checking the average prediction for the test data set ( A Balanced dataset)\ntest_predictions_1.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["display(test_predictions_1)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["#####################################################MODEL 2 #########################################################\n#Definition of the features with the win percentages of both the playing teams\nfeatureCols_2 = [\"WTeamID\",'1998_2005_win_percentage', '2006_2010_win_percentage', '2011_2015_win_percentage', '2016_2017_win_percentage']\n\nrandom_for_2 = LogisticRegression()\nassembler_2 = feature.VectorAssembler(inputCols=featureCols_2, outputCol=\"features\")\n\npipeline_2 = Pipeline(stages=[ assembler_2, random_for_2])\n\n# Run stages in pipeline and train model\nmodel_2 = pipeline_2.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["val_predictions_2 = model_2.transform(validationData)\ntest_predictions_2=model_2.transform(testData)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["#Accuracy for validation data- using period features\nprint(\"The AUC Metric for validation data set of model-2 \", evaluator.evaluate(val_predictions_2))\nprint(\"The AUC Metric for test data set of model-2 \", evaluator.evaluate(test_predictions_2))"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["val_predictions_2.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["test_predictions_2.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["###############################MODEL - 3 ##################################################\n\n#Defnition of Features - with all the match and team feautres, win and lose percetages and teh period win percetage feaures\nfeatureCols_3 = ['WTeamID','1998_2005_win_percentage', '2006_2010_win_percentage', '2011_2015_win_percentage', '2016_2017_win_percentage',\"W_win_percentage\",\"L_win_percentage\",\"DayNum\", \"Score_Diff\", \"Seed_Diff\", \"Loc\", \"NumOT\"]\n\n#Logistic Regression for all features\nrandom_for_3 = LogisticRegression()\n\nassembler_3=feature.VectorAssembler(inputCols=featureCols_3,outputCol=\"features\")\n# Chain labelIndexer, vecAssembler and NBmodel in a \npipeline_3 = Pipeline(stages=[ assembler_3, random_for_3])\n\n# Run stages in pipeline and train model\nmodel_3 = pipeline_3.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["val_predictions_3 = model_3.transform(validationData)\ntest_predictions_3 = model_3.transform(testData)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["#Accuracy for validation data- using all features\nprint(\"The AUC Metric for validation data set of model-3 \", evaluator.evaluate(val_predictions_3))\nprint(\"The AUC Metric for test data set of model-3 \", evaluator.evaluate(test_predictions_3))"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["val_predictions_3.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["test_predictions_3.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["display(test_predictions_3)"],"metadata":{},"outputs":[],"execution_count":56}],"metadata":{"name":"random_forest_models","notebookId":1148613301606246},"nbformat":4,"nbformat_minor":0}
