{"cells":[{"cell_type":"markdown","source":["#IST718 Project - Google and NCAA Women's Basketball Tournament Prediction\n\n#Logistic Regression Machine learning algorithm -2010 to 2017\n\n@authors\nSanjana Rajagopala,\nShefali Vajramatti,\nApoorva Rajendra Angre,\nSandya Madhavan"],"metadata":{}},{"cell_type":"code","source":["#IMPORT ALL THE REQUIRED PACKAGES\nimport pandas as pd\nfrom pyspark.ml import feature\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import classification\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SQLContext\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.sql import functions as fn\nfrom pyspark.sql.types import IntegerType\nimport numpy as np\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.ml.feature import StringIndexer"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Read the required data from the CSV files uploaded in the FileStore dbfs of the Databricks environment\nwteamDF = spark.read.csv(\"/FileStore/tables/WTeams.csv\", header=True, inferSchema= True)\nlteamDF = spark.read.csv(\"/FileStore/tables/WTeams.csv\", header=True, inferSchema= True)\n\n#Read the RegularSeasons CSV File\nregularSeasonsDF = spark.read.csv(\"/FileStore/tables/WRegularSeasonCompactResults.csv\", header=True, inferSchema= True)\n\n#Read the Seeds and Slots CSV Files\nseedsDF = spark.read.csv(\"/FileStore/tables/WNCAATourneySeeds_SampleTourney2018.csv\", header=True, inferSchema= True)\n\nslotsDF = spark.read.csv(\"/FileStore/tables/WNCAATourneySlots.csv\", header=True, inferSchema=True)\n\n#Read the PrelimData2018 CSV File\ndetailedDF = spark.read.csv(\"/FileStore/tables/WRegularSeasonDetailedResults_PrelimData2018.csv\", header=True, inferSchema= True)\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Convert into Pandas DF from sql.dataframe for initial manipulation of data\nwteamDF = wteamDF.toPandas()\nlteamDF = lteamDF.toPandas()\nregularSeasonsDF = regularSeasonsDF.toPandas()\nslotsDF = slotsDF.toPandas()\nseedsDF = seedsDF.toPandas()\ndetailedDF = detailedDF.toPandas()\n\n#Rename the columns\nwteamDF.columns = ['WTeamID', 'WTeamName']\nlteamDF.columns = ['LTeamID', 'LTeamName']\n\n#Maitain a copy of the original data\nNewseedsDF=seedsDF"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Create the DICTIONARY - team id,season as key and seed as value\nseedsdict={}\nfor row in NewseedsDF.iterrows():\n  seedsdict[(row[1][\"Season\"], row[1][\"TeamID\"])] = row[1][\"Seed\"]\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Merge the Season and team ID details-DetailedDF and dictionary used\n#Append 0 if there is no seed\ntemp_wCol = []\ntemp_lCol = []\nfor row in detailedDF.iterrows():\n  year = row[1]['Season']\n  wteamid = row[1]['WTeamID']\n  lteamid = row[1]['LTeamID']\n  if(seedsdict.has_key((year,wteamid))):\n    temp_wCol.append(seedsdict[(year,wteamid)])\n  else:\n    temp_wCol.append('0')\n  if(seedsdict.has_key((year,lteamid))):\n    temp_lCol.append(seedsdict[(year,lteamid)])\n  else:\n    temp_lCol.append('0')\n  "],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Add the corresponding seed values into the dataframe\ndetailedDF['WSeed'] = temp_wCol\ndetailedDF['LSeed'] = temp_lCol"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Define weights for the seeds of each team - Meaning keep the highest weight of 16 for the team with Seed 1\nweights_dict = {}\nj = 1\nweights_dict[0] = 0\nfor i in range(16,0,-1):\n  weights_dict[j] = i\n  j+=1"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#PRE_PROCESSING THE DATAFRAME \n\ntemp_win = []\nwseed_num = []\nlseed_num = []\ndiff_seed = []\nloc_col = []\ndiff_score = []\n\nfor row in detailedDF.iterrows():\n  \n  team_1 = row[1]['WTeamID']\n  team_2 = row[1]['LTeamID']\n  loc_val = row[1]['WLoc']\n  wseed = row[1]['WSeed']\n  lseed =row[1]['LSeed']\n  \n  #Maintain the win column value as 1 if the team with lower teamID has won in the match\n  if(team_1<team_2):\n    temp_win.append(1)\n  else:\n    temp_win.append(0)\n      \n    \n  #Give the highest weight when played in the home ground, least of outside home, medium vlaue otherwise   \n  if(loc_val == 'H'):\n    loc_col.append(3)\n  elif(loc_val == 'N'):\n    loc_col.append(2)\n  elif(loc_val=='A'):\n    loc_col.append(1)\n    \n  #Maintain the difference between seeds of the teams  \n  if(wseed == '0' and lseed == '0'):\n    temp_val = abs(weights_dict[0]- weights_dict[0])\n  elif(wseed=='0' and lseed != '0'):\n    temp_val = abs(weights_dict[0]- weights_dict[int(lseed[1:])])\n  elif(wseed != '0' and lseed == '0'):\n    temp_val = abs(weights_dict[int(wseed[1:])]- weights_dict[0])\n  else:\n    temp_val = abs(weights_dict[int(wseed[1:])] - weights_dict[int(lseed[1:])])\n  diff_seed.append(temp_val)\n  \n  #Maintain the column with difference between scores of the teams\n  diff_score.append(abs(row[1]['WScore'] - row[1]['LScore']))\n  "],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Add the above obtained lists as columns into the DF\ndetailedDF['WLProb'] = temp_win\ndetailedDF['Seed_Diff'] = diff_seed\ndetailedDF['Loc'] = loc_col\ndetailedDF['Score_Diff'] = diff_score"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Check the results of the pre-processing\ndetailedDF[:2]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Conversion into the Spark SQL Dataframe\nsqlCtx = SQLContext(sc)\nsql_compactDF = sqlCtx.createDataFrame(detailedDF)\n\n#Rename the result column with the name label so that all the algorithms can be applied without any problems\nsql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#FEATURE ENGINEERING\n\n#Definition of new features from existing data\n\n#Obtain the totalMatches played and win percentage of the team in respective season\n\nwDF = sql_compactDF.groupBy(['Season','WTeamID']).agg(fn.sum('label').alias('won'), fn.count('Season').alias('WCount'))\nlDF = sql_compactDF.groupBy(['Season','LTeamID']).agg(fn.count('Season').alias('LCount'))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["wDF.show()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["lDF.show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Rename and maintain a clean DF\nwDF = wDF.selectExpr(\"WTeamID as teamID\", \"Season\", \"won\", \"WCount\")\nlDF = lDF.selectExpr(\"LTeamID as teamID\", \"Season\", \"LCount\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#Create a DF of matches with the above combined details\nmatchDF = wDF.join(lDF, (wDF.teamID== lDF.teamID) & (wDF.Season==lDF.Season), how='right')"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["matchDF = matchDF.withColumn(\"totalMatches\", sum([matchDF[col] for col in ['WCount', 'LCount']]))\n#Computing the win percetage for the individaul teams\nmatchDF=matchDF.withColumn(\"winPercentage\", fn.col('WCount')/fn.col('totalMatches') )\n#Create Pandas DF only for this manipulation\n#Renaming and selecting required data - avoiding redundancy\nmatch_pd_DF = matchDF.toPandas()\nmatch_pd_DF = match_pd_DF.iloc[:,[0,1,8]]\nmatchDF = sqlCtx.createDataFrame(match_pd_DF)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#Count and display the DF to ensure the join has not missed any data rows and other details\ndisplay(matchDF)\n#Expect NaN because of the null values introduced during the join"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Add the details from matchDF to the initial integrated DF\n\nwinPercentage_DF = sql_compactDF.join(matchDF, (matchDF.teamID== sql_compactDF.WTeamID) & (sql_compactDF.Season==matchDF.Season), how='left').select('DayNum', sql_compactDF.Season, 'WTeamID', 'WScore', 'LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc', \"Score_Diff\",fn.col('winPercentage').alias('W_win_percentage'),'WFGM', 'WFGA','WFGM3','WFGA3','WFTM','WFTA','WOR','WDR','WAst','WTO','WStl','WBlk','WPF','LFGM', 'LFGA','LFGM3','LFGA3','LFTM','LFTA','LOR','LDR','LAst','LTO','LStl','LBlk','LPF') \n\nwinPercentage_DF = winPercentage_DF.join(matchDF, (matchDF.teamID== winPercentage_DF.LTeamID) & (winPercentage_DF.Season==matchDF.Season), how='left').select('DayNum', winPercentage_DF.Season, 'WTeamID', 'WScore', 'LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc' ,\"Score_Diff\",'W_win_percentage',fn.col('winPercentage').alias('L_win_percentage'), 'WFGM', 'WFGA','WFGM3','WFGA3','WFTM','WFTA','WOR','WDR','WAst','WTO','WStl','WBlk','WPF','LFGM', 'LFGA','LFGM3','LFGA3','LFTM','LFTA','LOR','LDR','LAst','LTO','LStl','LBlk','LPF' )"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["display(winPercentage_DF)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Obtain the percentage as per the periods - 2010 to 2015; 2016 to 2017\n#This further used as features in the models\n\ngroupedTeams_DF_1 = matchDF.where((fn.col('Season').cast(IntegerType())>=2010) & (fn.col('Season').cast(IntegerType())<=2015)).groupBy('teamID').agg(fn.avg('winPercentage').alias('2010_2015_win_percentage'))\n\n#Repeat the grouping for remianing periods\n\ngroupedTeams_DF_2 = matchDF.where((fn.col('Season').cast(IntegerType())>=2016) & (fn.col('Season').cast(IntegerType())<=2017)).groupBy('teamID').agg(fn.avg('winPercentage').alias('2016_2017_win_percentage')) "],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Removing null values \nwinPercentage_DF=winPercentage_DF.na.fill(0)\n\n#Display to check the final DF\ndisplay(winPercentage_DF)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Join the data frame with groupedTeams_DF_1&2\nwinPercentage_DF=groupedTeams_DF_1.join(winPercentage_DF, winPercentage_DF.WTeamID == groupedTeams_DF_1.teamID, how='right').select('DayNum', winPercentage_DF.Season, 'WTeamID', 'WScore','LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc' ,\"Score_Diff\",'W_win_percentage', 'L_win_percentage', 'WFGM', 'WFGA','WFGM3','WFGA3','WFTM','WFTA','WOR','WDR','WAst','WTO','WStl','WBlk','WPF','LFGM', 'LFGA','LFGM3','LFGA3','LFTM','LFTA','LOR','LDR','LAst','LTO','LStl','LBlk','LPF','2010_2015_win_percentage')\n\nwinPercentage_DF=groupedTeams_DF_2.join(winPercentage_DF, winPercentage_DF.WTeamID == groupedTeams_DF_2.teamID, how='right')\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Removing redundant columns\nwpandasDF=winPercentage_DF.toPandas()\nwpandasDF=wpandasDF.drop('teamID', axis=1)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Creating spark sql dataframe\nwinPercentage_DF=sqlCtx.createDataFrame(wpandasDF)\n#Removing null values\nwinPercentage_DF=winPercentage_DF.na.fill(0)\n"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["temp_DF = winPercentage_DF.select('DayNum', 'WTeamID', 'WScore','LTeamID', \"LScore\", 'NumOT', \"WSeed\", 'LSeed', 'label', 'Seed_Diff', 'Loc' ,\"Score_Diff\",'W_win_percentage', 'L_win_percentage', 'Season','2010_2015_win_percentage', '2016_2017_win_percentage',(fn.col('WFGM')/fn.col('WFGA')).alias('WGoals_ratio'),(fn.col('WFGM3')/fn.col('WFGA3')).alias('W3pointers_ratio'),(fn.col('WFTM')/fn.col('WFTA')).alias('WFreethrows_ratio'),(fn.col('WOR')+fn.col('WDR')+fn.col('WAst')+fn.col('WTO')+fn.col('WStl')+fn.col('WBlk')-fn.col('WPF')).alias('Win_accomplish'), (fn.col('LFGM')/fn.col('LFGA')).alias('LGoals_ratio'),(fn.col('LFGM3')/fn.col('LFGA3')).alias('L3pointers_ratio'),(fn.col('LFTM')/fn.col('LFTA')).alias('LFreethrows_ratio'),(fn.col('LOR')+fn.col('LDR')+fn.col('LAst')+fn.col('LTO')+fn.col('LStl')+fn.col('LBlk')-fn.col('LPF')).alias('Lose_accomplish'))"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["display(temp_DF)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["winPercentage_DF = temp_DF"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#Display and count to check the results\ndisplay(winPercentage_DF)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["#INFERENCE OF THE ADDED FEATURES\n\n#Checkimg the correlation between win percentages of each period with label\nwinPercentage_DF.select(fn.corr('2010_2015_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["winPercentage_DF.select(fn.corr('2016_2017_win_percentage', 'label')).show()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["#MACHINE LEARNING \n\n"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["\n#To replace na values as 0\nwinPercentage_DF = winPercentage_DF.na.fill(0)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["#display(winPercentage_DF)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["\n# Split dataset randomly into Training , Validation and Test Datasets\ntrainingData, validationData, testData = winPercentage_DF.randomSplit([0.6,0.3,0.1])"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["#####################################################MODEL 1 #########################################################\n#Definition of the features with the win percentages of year ranges 2019-15 and 2016-17\nfeatureCols_2 = [\"DayNum\", \"WTeamID\", \"Score_Diff\", \"Loc\", \"Seed_Diff\", \"NumOT\",'2010_2015_win_percentage', '2016_2017_win_percentage']\n\n\nlogisticReg_2 = LogisticRegression()\nassembler_2 = feature.VectorAssembler(inputCols=featureCols_2, outputCol=\"features\")\n\n# create a pipeline\npipeline_2 = Pipeline(stages=[assembler_2, logisticReg_2])\n\n# Run stages in pipeline and train model\nmodel_2 = pipeline_2.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["val_predictions_2 = model_2.transform(validationData)\ntest_predictions_2=model_2.transform(testData)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["#Define the evaluator to obtain the areaUnderROC or the AUC score of the model\nevaluator = BinaryClassificationEvaluator()"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["#Accuracy for validation data- using period features\nprint(\"The AUC Metric for validation data set of model-1 \", evaluator.evaluate(val_predictions_2))\nprint(\"The AUC Metric for test data set of model-1 \", evaluator.evaluate(test_predictions_2))"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["#Checking the average prediction for validation data set\nval_predictions_2.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["#Checking the average prediction for the test data set\ntest_predictions_2.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["###############################MODEL - 2 ##################################################\n\n#Defnition of Features - with all the match and team feautres, win and lose percetages and the period win percetage feaures\nfeatureCols_3 = [\"WTeamID\", \"Seed_Diff\",\"Score_Diff\", \"Loc\", \"W_win_percentage\", \"L_win_percentage\",\"2010_2015_win_percentage\",\"2016_2017_win_percentage\", \"NumOT\",\"WGoals_ratio\", 'W3pointers_ratio', 'WFreethrows_ratio', 'Win_accomplish', 'LGoals_ratio','L3pointers_ratio', 'LFreethrows_ratio', 'Lose_accomplish']\n\n#Logistic Regression for all features\nlogisticReg_3 = LogisticRegression()\n\nassembler_3=feature.VectorAssembler(inputCols=featureCols_3,outputCol=\"features\")\n# create a pipeline\npipeline_3 = Pipeline(stages=[assembler_3, logisticReg_3])\n\n# Run stages in pipeline and train model\nmodel_3 = pipeline_3.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["\nval_predictions_3 = model_3.transform(validationData)\ntest_predictions_3 = model_3.transform(testData)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["#Accuracy for validation data- using all features\nprint(\"The AUC Metric for validation data set of model-2 \", evaluator.evaluate(val_predictions_3))\nprint(\"The AUC Metric for test data set of model-2 \", evaluator.evaluate(test_predictions_3))"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["#Checking the average prediction for the validation data set\nval_predictions_3.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["#Checking the average prediction for the test data set#\ntest_predictions_3.select(fn.avg('prediction')).show()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["model_3.stages[1].coefficients"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["lr_features = model_3.stages[1]"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["###MODEL 3####\n\nlogisticReg_4 = LogisticRegression(maxIter=10)\n\nassembler_4=feature.VectorAssembler(inputCols=featureCols_3,outputCol=\"features\")\n\n"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["#PARAM_GRID BUILDER\n\nparamGrid_1 = ParamGridBuilder().addGrid(logisticReg_4.regParam, [0.01, 0.5, 2.0]).addGrid(logisticReg_4.elasticNetParam, [0.0, 0.5, 1.0]).addGrid(logisticReg_4.maxIter, [5, 10]).build()\n\n#CROSS_VALIDATOR\ncrossval =  CrossValidator(estimator=logisticReg_4, estimatorParamMaps=paramGrid_1, evaluator=evaluator, numFolds=5)\n\n# Run cross-validation, and choose the best set of parameters.\n#cvModel = crossval.fit(trainingData)\n\npipeline_4 = Pipeline(stages=[ assembler_4, crossval])\n"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["model_4 = pipeline_4.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["val_predictions_4 = model_4.transform(validationData)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["evaluator.evaluate(val_predictions_4)\n"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["test_predictions_4 = model_4.transform(testData)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["evaluator.evaluate(test_predictions_4)"],"metadata":{},"outputs":[],"execution_count":56}],"metadata":{"name":"logistic_regression_models","notebookId":1822547191590668},"nbformat":4,"nbformat_minor":0}
